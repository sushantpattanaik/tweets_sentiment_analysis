{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMnjk2HLf4G1"
   },
   "source": [
    "## tweets sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Objective 1: Get the most frequent entities from the tweets.\n",
    "Objective 2: Find out the sentiment/polarity of each author towards each of the entities.\n",
    "Sample Input:\n",
    "Assume we have only 4 tweets:\n",
    "Tweet1 by Author1: Pink Pearl Apples are tasty but Empire Apples are not.\n",
    "Tweet2 by Author2: Empire Apples are very tasty.\n",
    "Tweet3 by Author3: Pink Pearl Apples are not tasty.\n",
    "Tweet4 by Author1: Pink Pearl Apples smells really good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import json\n",
    " SentimentIntensityAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk # natural language toolkit, so this is the main library for your natural language processing\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "#what are stopwords \n",
    "#ans #which are very frequency but do not addant meansing \n",
    "#example===> is, there,this\n",
    "\n",
    "\n",
    "\n",
    "# later we will remove them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.words('english')#so it show me all these stopwords for english language\n",
    "# it is alredy inbulid\n",
    "\n",
    "# and also uses in different language[arabic,french,german]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1e5119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "#Strings in python are surrounded by either single quotation marks, or double quotation marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5b05725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation\n",
    "#what are the punctuation????\n",
    "#ans # these spacial characters['!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'] and \n",
    "#.....also this spacial charactors do not add any meaning to the meachine, probablythey are immatrial \n",
    "\n",
    "# later we will remove them also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OcVT2yi-grbR"
   },
   "source": [
    "**Import and Read the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "#JSON stands for JavaScript Object Notation\n",
    "#JSON is a lightweight format for storing and transporting data\n",
    "#JSON is often used when data is sent from a server to a web page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I1N2QXnHWCHg"
   },
   "outputs": [],
   "source": [
    "with open('/content/tweets.json') as jfile:\n",
    "  json_file = json.load(jfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NN4Xle7wgvzE"
   },
   "source": [
    "**Convert into Data Frame that easy to readable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CKdthgpSbrzH"
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "gO00i3-tbv5I",
    "outputId": "16e18ef3-c1f7-48af-a4ad-9f0302b4cb1d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_author</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1374140386071961602</th>\n",
       "      <td>Hematopoiesis News</td>\n",
       "      <td>⚕️ Scientists conducted a Phase II study of ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374032432173842437</th>\n",
       "      <td>Michael Wang, MD</td>\n",
       "      <td>This phase 2 Acalabrutinib-Venetoclax (AV) tri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373902876553048065</th>\n",
       "      <td>1stOncology</td>\n",
       "      <td>#NICE backs #AstraZenecas #Calquence for #CLL ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373656782367813635</th>\n",
       "      <td>Toby Eyre</td>\n",
       "      <td>#acalabrutinib is a valuable option in pts int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372941634334232586</th>\n",
       "      <td>Lymphoma Hub</td>\n",
       "      <td>NICE has recommended the use of acalabrutinib ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372927482278539265</th>\n",
       "      <td>David Ledger</td>\n",
       "      <td>NICE backs AstraZeneca’s Calquence for CLL htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372911723305394179</th>\n",
       "      <td>N Wales Cancer Forum</td>\n",
       "      <td>This is England for now - these decisions usua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372888121159868423</th>\n",
       "      <td>European Pharmaceutical Review</td>\n",
       "      <td>AstraZeneca’s Calquence (acalabrutinib), a che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372866915081797632</th>\n",
       "      <td>Graham Collins</td>\n",
       "      <td>Superstar @tobyeyre82 responding to the excell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372825553837944834</th>\n",
       "      <td>CLL Ireland</td>\n",
       "      <td>CLL patients all know the drug Ibrutinib and y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       tweet_author                                         tweet_text\n",
       "1374140386071961602              Hematopoiesis News  ⚕️ Scientists conducted a Phase II study of ac...\n",
       "1374032432173842437                Michael Wang, MD  This phase 2 Acalabrutinib-Venetoclax (AV) tri...\n",
       "1373902876553048065                     1stOncology  #NICE backs #AstraZenecas #Calquence for #CLL ...\n",
       "1373656782367813635                       Toby Eyre  #acalabrutinib is a valuable option in pts int...\n",
       "1372941634334232586                    Lymphoma Hub  NICE has recommended the use of acalabrutinib ...\n",
       "1372927482278539265                    David Ledger  NICE backs AstraZeneca’s Calquence for CLL htt...\n",
       "1372911723305394179            N Wales Cancer Forum  This is England for now - these decisions usua...\n",
       "1372888121159868423  European Pharmaceutical Review  AstraZeneca’s Calquence (acalabrutinib), a che...\n",
       "1372866915081797632                  Graham Collins  Superstar @tobyeyre82 responding to the excell...\n",
       "1372825553837944834                     CLL Ireland  CLL patients all know the drug Ibrutinib and y..."
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)\n",
    "##pandas. head () function is used to access the first n rows of a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5OYKCsgWg41W"
   },
   "source": [
    "**check null values**\n",
    "\n",
    "**Total no of unique writer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UlSqIIhgNDUI",
    "outputId": "07e1a30d-9066-4d8f-8de2-3c05fd62c579"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total no of null valus in the data:\n",
      " tweet_author    0\n",
      "tweet_text      0\n",
      "dtype: int64\n",
      "total no tweet author: 9292\n"
     ]
    }
   ],
   "source": [
    "print('total no of null valus in the data:\\n',df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ft4Cf7qFhI0H"
   },
   "source": [
    "# 2) Clean the data and convert them into Machine Readable Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#RegEx, or Regular Expression, is a sequence of characters that forms a search pattern.\n",
    "#RegEx can be used to check if a string contains the specified search pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_8bF_BjiRX-u"
   },
   "outputs": [],
   "source": [
    "def dataclean_data():\n",
    "  data = data.lower()\n",
    "  data = re.sub(r'[^(a-zA-Z)\\s]','', data)\n",
    "    #The sub() function replaces the matches with the text of your choice\n",
    "    \n",
    "    '''^ Starts with \"^hello\"\n",
    "[a-zA-Z] Returns a match for any character alphabetically between a and z, lower case OR upper case\n",
    "\\s Returns a match where the string contains a white space character \"\\s\" '''\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    " #     remove urls\n",
    "    data = re.sub(r'http\\S+', \" \", data)\n",
    "\n",
    "'''\\S Returns a match where the string DOES NOT contain a white space character \"\\S\"\n",
    "+ One or more occurrences \"he.+o\" '''\n",
    "\n",
    "\n",
    " \n",
    "    \n",
    "    #     remove mentions\n",
    "    data = re.sub(r'@\\w+',' ',data)\n",
    "    \n",
    "'''\\w Returns a match where the string contains any word characters (characters from a to Z, digits from 0-9, and the underscore _ character)\t\"\\w\"\n",
    "+ One or more occurrences \"he.+o\"  '''\n",
    "    \n",
    "    \n",
    "    \n",
    " #     remove hastags\n",
    "  data = re.sub(r'#\\w+', ' ',data)\n",
    "    \n",
    "'''\\w Returns a match where the string contains any word characters (characters from a to Z, digits from 0-9, and the underscore _ character)\t\"\\w\"\n",
    "+ One or more occurrences \"he.+o\"  '''    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     remove digits\n",
    "  data = re.sub(r'\\d+()', ' ', data)\n",
    "\n",
    "'''\\d Returns a match where the string contains digits (numbers from 0-9) \"\\d\"\n",
    "[0-9]\tReturns a match for any digit between 0 and 9\n",
    "() Capture and group  '''\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#     remove html tags and umber\n",
    "  data = re.sub('r<.*?>',' ', data)\n",
    "\n",
    "'''* Zero or more occurrences \"he.*o\" '''\n",
    "    \n",
    "    \n",
    " #     remove stop words \n",
    "  data = data.split()\n",
    "  data = \" \".join([word for word in data if not word in stopword])\n",
    "#The join() method takes all items in an iterable and joins them into one string.\n",
    "  return data\n",
    "df['tweet_text']=df['tweet_text'].apply(lambda x:clean_data(x))\n",
    "#Pandas.apply allow the users to pass a function and apply it on every single value of the Pandas series. It comes as a huge improvement for the pandas library as this function helps to segregate data according to the conditions required due to which it is efficiently used in data science and machine learning.\n",
    "#https://www.geeksforgeeks.org/python-pandas-apply/\n",
    "\n",
    "#########################\n",
    "def remove_punct(text):\n",
    "    text  = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub('[0-9]+', '', text)\n",
    "    '''[0-9] Returns a match for any digit between 0 and 9 \n",
    "    + One or more occurrences \"he.+o\"'''\n",
    "    #he sub() function replaces the matches with the text of your choice\n",
    "    return text\n",
    "\n",
    "df['tweet_text']= df['tweet_text'].apply(lambda x: remove_punct(x))\n",
    "\n",
    "\n",
    "##############################\n",
    "#Tokenization of the text data\n",
    "def tokenization(text):\n",
    "    text = re.split('\\W+', text)\n",
    "    '''\\W Returns a match where the string DOES NOT contain any word characters\"\\W\" '''\n",
    "    #split()Returns a list where the string has been split at each match\n",
    "    return text\n",
    "df['tweet_text'] = df['tweet_text'].apply(lambda x: tokenization(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nopunc = [char for char in mess if char not in string.punctuation] ???\n",
    "#ans# i am saying char for char in mess if char not in string.punctuation \n",
    "#.....what is string.punctuation contains??==>only punctuation ['!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~']\n",
    "#when i am saying not string.punctuation it means it will not select the punctuation but it will select all the other thing\n",
    "#.......wich means punctuations would be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"The rain in Spain\"\n",
    "x = re.sub(\"\\s\", \"9\", txt)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rain in Spain\n"
     ]
    }
   ],
   "source": [
    "txt = \"The rain in Spain\"\n",
    "x = re.sub('[^(a-zA-Z)\\s]','', txt)#The sub() function replaces the matches with the text of your choice:\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"The rain in Spain\"\n",
    "x = re.split(\"\\s\", txt)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['welcome', 'to', 'the', 'jungle']\n"
     ]
    }
   ],
   "source": [
    "txt = \"welcome to the jungle\"\n",
    "\n",
    "x = txt.split()\n",
    "#Strings in python are surrounded by either single quotation marks, or double quotation marks.\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John Peter Vicky\n"
     ]
    }
   ],
   "source": [
    "myTuple = (\"John\", \"Peter\", \"Vicky\")\n",
    "\n",
    "x = \" \".join(myTuple)#The join() method takes all items in an iterable and joins them into one string.\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"The rain in Spain\"\n",
    "x = re.sub(\"\\s\", \"9\", txt)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NMHqh9YF7761"
   },
   "source": [
    "\n",
    "\n",
    "#**Get the most frequent entities from the tweets. and we convert them into csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0hYU7qsc8KsX"
   },
   "outputs": [],
   "source": [
    "df1=df['tweet_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZpgnEFmhdFv"
   },
   "source": [
    "**Steaming anf Lemitization of the code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WNYcptKl-SpK"
   },
   "outputs": [],
   "source": [
    "ps = nltk.PorterStemmer()\n",
    "def stemming(text):\n",
    "    text = [ps.stem(word) for word in text]\n",
    "    return text\n",
    "df1 = df1.apply(lambda x: stemming(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q18TzaGy-SZh"
   },
   "outputs": [],
   "source": [
    "wn = nltk.WordNetLemmatizer()\n",
    "def lemmatizer(text):\n",
    "    text = [wn.lemmatize(word) for word in text]\n",
    "    return text\n",
    "df1= df1.apply(lambda x: lemmatizer(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EpS94QhCFQ5Z"
   },
   "source": [
    "**Stanford NLP NER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fvxGDcciTH6f"
   },
   "outputs": [],
   "source": [
    "from nltk.tag.stanford import StanfordNERTagger\n",
    "\n",
    "st = StanfordNERTagger('/content/stanford-ner-2018-10-16/classifiers/english.all.3class.distsim.crf.ser.gz',\n",
    "                       '/content/stanford-ner-2018-10-16/stanford-ner.jar',\n",
    "                       encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O7GCD8Oaynvm"
   },
   "outputs": [],
   "source": [
    "classified_text = st.tag(df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions used\n",
    "Here we will pass the inputs through the list as a dictionary data structure.\n",
    "\n",
    "groupby(): groupby() is used to group the data based on the column values.\n",
    "size(): This is used to get the size of the data frame.\n",
    "sort_values(): This function sorts a data frame in Ascending or Descending order of passed Column.\n",
    "The task is straightforward, for a given dataframe first we need to group by any column as per requirement and then arrange the grouped values of the column according to their size. By size here we mean how many times a value has appeared in a column or its frequency.\n",
    "\n",
    "\n",
    "\n",
    "https://www.geeksforgeeks.org/how-to-sort-grouped-pandas-dataframe-by-group-size/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "j5GcidKrxF-f",
    "outputId": "810ca926-124c-42c4-df9b-22a406b657d6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity Name</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acalabrutinib</td>\n",
       "      <td>1306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>calquenc</td>\n",
       "      <td>893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>patient</td>\n",
       "      <td>790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>covid</td>\n",
       "      <td>694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>astrazeneca</td>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cll</td>\n",
       "      <td>562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>trial</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lymphocyt</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>chronic</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>leukemia</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Entity Name  Frequency\n",
       "0  acalabrutinib       1306\n",
       "1       calquenc        893\n",
       "2        patient        790\n",
       "3          covid        694\n",
       "4    astrazeneca        599\n",
       "5            cll        562\n",
       "6          trial        425\n",
       "7      lymphocyt        388\n",
       "8        chronic        351\n",
       "9       leukemia        342"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity= pd.DataFrame(classified_text,columns=['Entity Name','Entity Type'])\n",
    "\n",
    "#Here We Remove Entities_type column from data we does not requierd this but the help to recgonized the type of entity\n",
    "\n",
    "all_entities = (entity.groupby(by=['Entity Name'])\n",
    "                          .size()\n",
    "                          .sort_values(ascending=False)\n",
    "                          .reset_index().rename(columns={0 : 'Frequency'}))\n",
    "all_entities.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zyXBXnhXDzgR"
   },
   "outputs": [],
   "source": [
    "all_entities.to_csv('entity_csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vF2pCS9fOG_u"
   },
   "source": [
    "# 3) Find out the sentiment/polarity of each author towards each of the entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "#TextBlob module is a Python library and offers a simple API to access its methods \n",
    "#...and perform basic NLP tasks. It is built on the top of NLTK module.\n",
    "\n",
    "#Some terms that will be frequently used are\n",
    "#Corpus – Body of text, singular. Corpora is the plural of this.\n",
    "#Lexicon – Words and their meanings.\n",
    "T#oken "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Jp7kbMOa71l"
   },
   "outputs": [],
   "source": [
    "df['tweet_text'] = df['tweet_text'].astype('str')\n",
    "def get_polarity(text):\n",
    "  return TextBlob(text).sentiment.polarity\n",
    "'''In short, text polarity is a measure of how negative or how positive a piece\n",
    "of text is. Polarity is the measure of the overall combination of the positive \n",
    "and negative emotions in a sentence. It’s notoriously hard for computers to predict this, \n",
    "in fact it’s even hard for people to predict this over text.'''\n",
    "\n",
    "df['Polarity'] = df['tweet_text'].apply(get_polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yT88Ph7IbiKD"
   },
   "outputs": [],
   "source": [
    "df.to_csv('sentiment_polarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "52Z_HOhUcBjK",
    "outputId": "a2aa3cff-d1b8-4755-ce92-afc4ca35de25",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_author</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1374140386071961602</th>\n",
       "      <td>Hematopoiesis News</td>\n",
       "      <td>['scientists', 'conducted', 'phase', 'ii', 'st...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374032432173842437</th>\n",
       "      <td>Michael Wang, MD</td>\n",
       "      <td>['phase', 'acalabrutinibvenetoclax', 'av', 'tr...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373902876553048065</th>\n",
       "      <td>1stOncology</td>\n",
       "      <td>['nice', 'backs', 'astrazenecas', 'calquence',...</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373656782367813635</th>\n",
       "      <td>Toby Eyre</td>\n",
       "      <td>['acalabrutinib', 'valuable', 'option', 'pts',...</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372941634334232586</th>\n",
       "      <td>Lymphoma Hub</td>\n",
       "      <td>['nice', 'recommended', 'use', 'acalabrutinib'...</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372927482278539265</th>\n",
       "      <td>David Ledger</td>\n",
       "      <td>['nice', 'backs', 'astrazenecas', 'calquence',...</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372911723305394179</th>\n",
       "      <td>N Wales Cancer Forum</td>\n",
       "      <td>['england', 'decisions', 'usually', 'come', 'w...</td>\n",
       "      <td>-0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372888121159868423</th>\n",
       "      <td>European Pharmaceutical Review</td>\n",
       "      <td>['astrazenecas', 'calquence', 'acalabrutinib',...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372866915081797632</th>\n",
       "      <td>Graham Collins</td>\n",
       "      <td>['superstar', 'tobyeyre', 'responding', 'excel...</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372825553837944834</th>\n",
       "      <td>CLL Ireland</td>\n",
       "      <td>['cll', 'patients', 'know', 'drug', 'ibrutinib...</td>\n",
       "      <td>0.045455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       tweet_author  ...  Polarity\n",
       "1374140386071961602              Hematopoiesis News  ...  0.000000\n",
       "1374032432173842437                Michael Wang, MD  ...  0.000000\n",
       "1373902876553048065                     1stOncology  ...  0.600000\n",
       "1373656782367813635                       Toby Eyre  ...  0.100000\n",
       "1372941634334232586                    Lymphoma Hub  ...  0.600000\n",
       "1372927482278539265                    David Ledger  ...  0.600000\n",
       "1372911723305394179            N Wales Cancer Forum  ... -0.250000\n",
       "1372888121159868423  European Pharmaceutical Review  ...  0.000000\n",
       "1372866915081797632                  Graham Collins  ...  0.800000\n",
       "1372825553837944834                     CLL Ireland  ...  0.045455\n",
       "\n",
       "[10 rows x 3 columns]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ynVRWh5_gOeS"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP_Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
